{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sunset-ceremony",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_int(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: int) -> mediapipe.python._framework_bindings.packet.Packet\n\nInvoked with: 0.5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-97cf923a63d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m720\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#height\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhtm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetectionCon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxHands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#making object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AI-Virtual-Paint\\handtrackingmodule.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mode, maxHands, detectionCon, trackCon)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackCon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrackCon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmpHands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhands\u001b[0m\u001b[1;31m#initializing hands module for the instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmpHands\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxHands\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectionCon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackCon\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#object for Hands for a particular instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmpDraw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing_utils\u001b[0m\u001b[1;31m#object for Drawing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtipIds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programdata\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\mediapipe\\python\\solutions\\hands.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, static_image_mode, max_num_hands, model_complexity, min_detection_confidence, min_tracking_confidence)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mhands\u001b[0m\u001b[1;31m#min_tracking_confidence.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m--> 114\u001b[1;33m     super().__init__(\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[0mbinary_graph_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_BINARYPB_FILE_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         side_inputs={\n",
      "\u001b[1;32mD:\\programdata\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, binary_graph_path, graph_config, calculator_params, side_inputs, outputs)\u001b[0m\n\u001b[0;32m    256\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserve_output_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m     self._input_side_packets = {\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_side_input_type_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mside_inputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programdata\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     self._input_side_packets = {\n\u001b[1;32m--> 259\u001b[1;33m         \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_side_input_type_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mside_inputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     }\n",
      "\u001b[1;32mD:\\programdata\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36m_make_packet\u001b[1;34m(self, packet_data_type, data)\u001b[0m\n\u001b[0;32m    511\u001b[0m           data, image_format=image_frame.ImageFormat.SRGB)\n\u001b[0;32m    512\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacket_creator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpacket_data_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m   def _get_packet_content(self, packet_data_type: _PacketDataType,\n",
      "\u001b[1;31mTypeError\u001b[0m: create_int(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: int) -> mediapipe.python._framework_bindings.packet.Packet\n\nInvoked with: 0.5"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import handtrackingmodule as htm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "overlayList=[]#list to store all the images\n",
    "\n",
    "brushThickness = 25\n",
    "eraserThickness = 100\n",
    "drawColor=(255,0,255)#setting purple color\n",
    "\n",
    "xp, yp = 0, 0\n",
    "imgCanvas = np.zeros((720, 1280, 3), np.uint8)# defining canvas\n",
    "\n",
    "#images in header folder\n",
    "folderPath=\"Header\"\n",
    "myList=os.listdir(folderPath)#getting all the images used in code\n",
    "#print(myList)\n",
    "for imPath in myList:#reading all the images from the folder\n",
    "    image=cv2.imread(f'{folderPath}/{imPath}')\n",
    "    overlayList.append(image)#inserting images one by one in the overlayList\n",
    "header=overlayList[0]#storing 1st image \n",
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(3,1280)#width\n",
    "cap.set(4,720)#height\n",
    "\n",
    "detector = htm.handDetector(detectionCon=0.50,maxHands=1)#making object\n",
    "\n",
    "while True:\n",
    "\n",
    "    # 1. Import image\n",
    "    success, img = cap.read()\n",
    "    img=cv2.flip(img,1)#for neglecting mirror inversion\n",
    "    \n",
    "    # 2. Find Hand Landmarks\n",
    "    img = detector.findHands(img)#using functions fo connecting landmarks\n",
    "    lmList,bbox = detector.findPosition(img, draw=False)#using function to find specific landmark position,draw false means no circles on landmarks\n",
    "    \n",
    "    if len(lmList)!=0:\n",
    "        #print(lmList)\n",
    "        x1, y1 = lmList[8][1],lmList[8][2]# tip of index finger\n",
    "        x2, y2 = lmList[12][1],lmList[12][2]# tip of middle finger\n",
    "        \n",
    "        # 3. Check which fingers are up\n",
    "        fingers = detector.fingersUp()\n",
    "        #print(fingers)\n",
    "\n",
    "        # 4. If Selection Mode - Two finger are up\n",
    "        if fingers[1] and fingers[2]:\n",
    "            xp,yp=0,0\n",
    "            #print(\"Selection Mode\")\n",
    "            #checking for click\n",
    "            if y1 < 125:\n",
    "                if 250 < x1 < 450:#if i m clicking at purple brush\n",
    "                    header = overlayList[0]\n",
    "                    drawColor = (255, 0, 255)\n",
    "                elif 550 < x1 < 750:#if i m clicking at blue brush\n",
    "                    header = overlayList[1]\n",
    "                    drawColor = (255, 0, 0)\n",
    "                elif 800 < x1 < 950:#if i m clicking at green brush\n",
    "                    header = overlayList[2]\n",
    "                    drawColor = (0, 255, 0)\n",
    "                elif 1050 < x1 < 1200:#if i m clicking at eraser\n",
    "                    header = overlayList[3]\n",
    "                    drawColor = (0, 0, 0)\n",
    "            cv2.rectangle(img, (x1, y1 - 25), (x2, y2 + 25), drawColor, cv2.FILLED)#selection mode is represented as rectangle\n",
    "\n",
    "\n",
    "        # 5. If Drawing Mode - Index finger is up\n",
    "        if fingers[1] and fingers[2] == False:\n",
    "            cv2.circle(img, (x1, y1), 15, drawColor, cv2.FILLED)#drawing mode is represented as circle\n",
    "            #print(\"Drawing Mode\")\n",
    "            if xp == 0 and yp == 0:#initially xp and yp will be at 0,0 so it will draw a line from 0,0 to whichever point our tip is at\n",
    "                xp, yp = x1, y1 # so to avoid that we set xp=x1 and yp=y1\n",
    "            #till now we are creating our drawing but it gets removed as everytime our frames are updating so we have to define our canvas where we can draw and show also\n",
    "            \n",
    "            #eraser\n",
    "            if drawColor == (0, 0, 0):\n",
    "                cv2.line(img, (xp, yp), (x1, y1), drawColor, eraserThickness)\n",
    "                cv2.line(imgCanvas, (xp, yp), (x1, y1), drawColor, eraserThickness)\n",
    "            else:\n",
    "                cv2.line(img, (xp, yp), (x1, y1), drawColor, brushThickness)#gonna draw lines from previous coodinates to new positions \n",
    "                cv2.line(imgCanvas, (xp, yp), (x1, y1), drawColor, brushThickness)\n",
    "            xp,yp=x1,y1 # giving values to xp,yp everytime \n",
    "           \n",
    "           #merging two windows into one imgcanvas and img\n",
    "    \n",
    "    # 1 converting img to gray\n",
    "    imgGray = cv2.cvtColor(imgCanvas, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 2 converting into binary image and thn inverting\n",
    "    _, imgInv = cv2.threshold(imgGray, 50, 255, cv2.THRESH_BINARY_INV)#on canvas all the region in which we drew is black and where it is black it is cosidered as white,it will create a mask\n",
    "    \n",
    "    imgInv = cv2.cvtColor(imgInv,cv2.COLOR_GRAY2BGR)#converting again to gray bcoz we have to add in a RGB image i.e img\n",
    "    \n",
    "    #add original img with imgInv ,by doing this we get our drawing only in black color\n",
    "    img = cv2.bitwise_and(img,imgInv)\n",
    "    \n",
    "    #add img and imgcanvas,by doing this we get colors on img\n",
    "    img = cv2.bitwise_or(img,imgCanvas)\n",
    "\n",
    "\n",
    "    #setting the header image\n",
    "    img[0:125,0:1280]=header# on our frame we are setting our JPG image acc to H,W of jpg images\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    #cv2.imshow(\"Canvas\", imgCanvas)\n",
    "    #cv2.imshow(\"Inv\", imgInv)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-frost",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-dictionary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
